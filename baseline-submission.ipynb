{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn import impute","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-19T03:21:57.887064Z","iopub.execute_input":"2023-12-19T03:21:57.887459Z","iopub.status.idle":"2023-12-19T03:22:00.665479Z","shell.execute_reply.started":"2023-12-19T03:21:57.887430Z","shell.execute_reply":"2023-12-19T03:22:00.664235Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/train.csv')\n# test = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T03:22:00.670770Z","iopub.execute_input":"2023-12-19T03:22:00.671362Z","iopub.status.idle":"2023-12-19T03:22:21.743709Z","shell.execute_reply.started":"2023-12-19T03:22:00.671325Z","shell.execute_reply":"2023-12-19T03:22:21.742475Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# test preprocessing helper functions\ndef binary(x):\n    return np.int8(1) if np.isnan(x) else np.int8(0)\n\n# preprocessing test dataset\ndef preprocessing_data(data):\n    #unnecessary cols ['row_id']\n    data.drop(columns=['row_id'], inplace=True)\n    \n    #missing values overmultiples rows\n    data.dropna(subset = ['imbalance_size', 'reference_price', 'matched_size',\n                       'bid_price', 'ask_price','wap'],\n                inplace = True)\n    \n    #(0/1) flags for imputed data points\n    data['far_price_missing'] = data['far_price'].apply(binary)\n    data['near_price_missing'] = data['near_price'].apply(binary)\n    \n    #data scaling\n    col_to_scale = [\n         'imbalance_size',\n         'reference_price',\n         'matched_size',\n         'far_price',\n         'near_price',\n         'bid_price',\n         'bid_size',\n         'ask_price',\n         'ask_size',\n         'wap',\n         'far_price_missing',\n         'near_price_missing'\n                    ]\n    scaler = MinMaxScaler(feature_range=(0, 1)).set_output(transform='pandas')\n    data[col_to_scale] = scaler.fit_transform(data[col_to_scale])\n\n    #inference missing price data\n    imputer = impute.IterativeImputer(random_state=21)\n    imputer.set_output(transform='pandas')\n    data = imputer.fit_transform(data)\n    \n    \n    #get_dummies\n    cols_to_dummies = [\n        'stock_id',\n        'date_id',\n        'seconds_in_bucket',\n        'imbalance_buy_sell_flag'\n        ]\n    data = pd.get_dummies(data, \n                       columns=cols_to_dummies,\n                       sparse=True, \n                       drop_first=True, \n                       dtype=np.int8)\n    \n    return data","metadata":{"execution":{"iopub.status.busy":"2023-12-19T03:22:21.745243Z","iopub.execute_input":"2023-12-19T03:22:21.745615Z","iopub.status.idle":"2023-12-19T03:22:21.757759Z","shell.execute_reply.started":"2023-12-19T03:22:21.745582Z","shell.execute_reply":"2023-12-19T03:22:21.756601Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Helper functions\n\ndef generate_batch(X, y, chunksize):\n    start = 0\n    while start < len(X):\n        end = min(start + chunksize, len(X))\n        X_chunk, y_chunk = X[start:end], y[start:end]\n        yield X_chunk, y_chunk\n        start += chunksize\n        \ndef batch_generator_test(X, chunk_size):\n    start = 0\n    while start < len(X):\n        end = min(start + chunk_size, len(X))\n        X_chunk = X[start:end]\n        yield X_chunk\n        start += chunk_size\n        \ndef train_model(model, X, y):\n    batch_generator = generate_batch(X, y, chunksize=10000)\n    scores = []\n    for X_chunk, y_chunk in batch_generator:\n        model.partial_fit(X_chunk, y_chunk)\n    \n    return model\n\ndef scoring(train_model, X, y):\n    batch_generator = generate_batch(X, y, chunksize=10000)\n    scores = []\n    for X_chunk, y_chunk in batch_generator:\n        scores.append(mean_absolute_error(y_chunk, train_model.predict(X_chunk)))\n        print(mean_absolute_error(y_chunk, train_model.predict(X_chunk)))\n    \n    return scores\n\ndef save_predictions(train_model, X, chunk_size=10000):\n    predictions = []\n    for X_chunk in batch_generator_test(X, chunk_size=10000):\n        predictions += train_model.predict(X_chunk).tolist()\n    return pd.DataFrame(predictions)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T03:22:21.760534Z","iopub.execute_input":"2023-12-19T03:22:21.760922Z","iopub.status.idle":"2023-12-19T03:22:21.777346Z","shell.execute_reply.started":"2023-12-19T03:22:21.760888Z","shell.execute_reply":"2023-12-19T03:22:21.776018Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import SGDRegressor\nmodel = SGDRegressor(loss='huber', epsilon=0.1, penalty='l1', fit_intercept=True,\n                     validation_fraction=.3, tol=1e-2)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T03:22:21.779360Z","iopub.execute_input":"2023-12-19T03:22:21.779776Z","iopub.status.idle":"2023-12-19T03:22:21.791087Z","shell.execute_reply.started":"2023-12-19T03:22:21.779743Z","shell.execute_reply":"2023-12-19T03:22:21.789938Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# baseline_submission\nimport optiver2023\n# optiver2023.make_env.func_dict['__called__'] = False\n\nenv = optiver2023.make_env()\niter_test = env.iter_test()\n\n\ncounter = 0\nfor (test, revealed_targets, sample_prediction) in iter_test:\n    test_ = preprocessing_data(test)\n    train = preprocessing_data(pd.read_csv('/kaggle/input/optiver-trading-at-the-close/train.csv'))\n    common_features = list(set(train.columns) & set(test_.columns))\n    X = train[common_features]\n    y = train['target']\n    baseline_model = train_model(model, X, y)\n    sample_prediction['target'] = model.predict(test_[common_features])\n    env.predict(sample_prediction)\n    counter += 1","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]}]}